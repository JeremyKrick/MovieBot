{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/site-packages (0.27.6)\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/1e/9f/385c25502f437686e4aa715969e5eaf5c2cb5e5ffa7c5cdd52f3c6ae967a/openai-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/site-packages (from openai) (2.30.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.6\n",
      "    Uninstalling openai-0.27.6:\n",
      "      Successfully uninstalled openai-0.27.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandasai 0.2.11 requires openai<0.28.0,>=0.27.5, but you have openai 0.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed openai-0.28.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install langchain\n",
    "! pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data\n",
    "\n",
    "Our selection of data was narrowed down by our approach to correlate movie actors and the movie lines that they spoke. We used the Cornell Movie-Dialogs Corpus, which is a collection of metadata-rich conversations extracted from raw movie scripts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset - movie_lines.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line ID</th>\n",
       "      <th>Character ID</th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Character Name</th>\n",
       "      <th>Text of Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Line ID Character ID Movie ID Character Name Text of Utterance\n",
       "0   L1045           u0       m0         BIANCA    They do not!\\n\n",
       "1   L1044           u2       m0        CAMERON     They do to!\\n\n",
       "2    L985           u0       m0         BIANCA      I hope so.\\n\n",
       "3    L984           u2       m0        CAMERON       She okay?\\n\n",
       "4    L925           u0       m0         BIANCA       Let's go.\\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the movie_lines.txt file\n",
    "file_path = 'nlp_group_movie_dataset/movie_lines.txt'\n",
    "# Initialize empty lists to store the data\n",
    "lineID = []\n",
    "characterID = []\n",
    "movieID = []\n",
    "character_name = []\n",
    "text_of_utterance = []\n",
    "# Read first line in the file\n",
    "with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    for line in f:\n",
    "        # Split each line using ' +++$+++ ' as the delimiter\n",
    "        line = line.split(' +++$+++ ')\n",
    "        # Extract the fields\n",
    "        lineID.append(line[0])\n",
    "        characterID.append(line[1])\n",
    "        movieID.append(line[2])\n",
    "        character_name.append(line[3])\n",
    "        text_of_utterance.append(line[4])\n",
    "    f.close()\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "# df = pd.DataFrame({'Line ID': lineID, 'Character ID': characterID, 'Movie ID': movieID, 'Character Name': character_name, 'Text of Utterance': text_of_utterance})\n",
    "df = pd.DataFrame({'Line ID': lineID, 'Character ID': characterID, 'Movie ID': movieID, 'Character Name': character_name, 'Text of Utterance': text_of_utterance})\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset - movie_characters_metadata.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the movie_lines.txt file\n",
    "file_path = 'nlp_group_movie_dataset/movie_characters_metadata.txt'\n",
    "# Initialize empty lists to store the data\n",
    "#characterID = []\n",
    "character_name = []\n",
    "movieID = []\n",
    "movie_title = []\n",
    "# Read first line in the file\n",
    "with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    for line in f:\n",
    "        # Split each line using ' +++$+++ ' as the delimiter\n",
    "        line = line.split(' +++$+++ ')\n",
    "        # Extract the fields\n",
    "        # lineID.append(line[0])\n",
    "        # characterID.append(line[1])\n",
    "        character_name.append(line[1])\n",
    "        movieID.append(line[2])\n",
    "        movie_title.append(line[3])\n",
    "    f.close()\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "# df = pd.DataFrame({'Line ID': lineID, 'Character ID': characterID, 'Movie ID': movieID, 'Character Name': character_name, 'Text of Utterance': text_of_utterance})\n",
    "df2 = pd.DataFrame({'Movie ID': movieID, 'Character Name': character_name, 'Movie Title': movie_title})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line ID</th>\n",
       "      <th>Character ID</th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Character Name</th>\n",
       "      <th>Text of Utterance</th>\n",
       "      <th>Movie Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!\\n</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.\\n</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.\\n</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.\\n</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Line ID Character ID Movie ID Character Name   \n",
       "0   L1045           u0       m0         BIANCA  \\\n",
       "1    L985           u0       m0         BIANCA   \n",
       "2    L925           u0       m0         BIANCA   \n",
       "3    L872           u0       m0         BIANCA   \n",
       "4    L870           u0       m0         BIANCA   \n",
       "\n",
       "                                   Text of Utterance   \n",
       "0                                     They do not!\\n  \\\n",
       "1                                       I hope so.\\n   \n",
       "2                                        Let's go.\\n   \n",
       "3   Okay -- you're gonna need to learn how to lie.\\n   \n",
       "4  I'm kidding.  You know how sometimes you just ...   \n",
       "\n",
       "                  Movie Title  \n",
       "0  10 things i hate about you  \n",
       "1  10 things i hate about you  \n",
       "2  10 things i hate about you  \n",
       "3  10 things i hate about you  \n",
       "4  10 things i hate about you  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two DataFrames on 'Movie ID' and 'Character Name'\n",
    "combined_df = pd.merge(df, df2, on=['Movie ID', 'Character Name'], how='outer')\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line ID</th>\n",
       "      <th>Character ID</th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Character Name</th>\n",
       "      <th>Text of Utterance</th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>process_utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!\\n</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>they do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.\\n</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>i hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.\\n</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.\\n</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>okay  you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>i'm kidding.  you know how sometimes you just ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Line ID Character ID Movie ID Character Name   \n",
       "0   L1045           u0       m0         BIANCA  \\\n",
       "1    L985           u0       m0         BIANCA   \n",
       "2    L925           u0       m0         BIANCA   \n",
       "3    L872           u0       m0         BIANCA   \n",
       "4    L870           u0       m0         BIANCA   \n",
       "\n",
       "                                   Text of Utterance   \n",
       "0                                     They do not!\\n  \\\n",
       "1                                       I hope so.\\n   \n",
       "2                                        Let's go.\\n   \n",
       "3   Okay -- you're gonna need to learn how to lie.\\n   \n",
       "4  I'm kidding.  You know how sometimes you just ...   \n",
       "\n",
       "                  Movie Title   \n",
       "0  10 things i hate about you  \\\n",
       "1  10 things i hate about you   \n",
       "2  10 things i hate about you   \n",
       "3  10 things i hate about you   \n",
       "4  10 things i hate about you   \n",
       "\n",
       "                                   process_utterance  \n",
       "0                                       they do not!  \n",
       "1                                         i hope so.  \n",
       "2                                          let's go.  \n",
       "3       okay  you're gonna need to learn how to lie.  \n",
       "4  i'm kidding.  you know how sometimes you just ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert words to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove new lines\n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace('\\r', '')\n",
    "    text = text.replace('\\t', '')\n",
    "    text = text.replace('...', '')\n",
    "    text = text.replace('--', '')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Remove unprocessed text\n",
    "combined_df['process_utterance'] = combined_df['Text of Utterance'].apply(preprocess_text)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EDA on: movie_lines.txt df\n",
      "Number of unique character names: 5356\n",
      "Number of unique movies: 617\n",
      "Number of unique character IDs: 9035\n",
      "\n",
      "EDA on: movie_characters_metadata.txt df\n",
      "Number of unique character names: 5356\n",
      "Number of unique movies: 617\n",
      "\n",
      "EDA on: Merged dataframe\n",
      "Number of unique character names: 5356\n",
      "Number of unique movies: 617\n",
      "Number of unique character IDs: 9035\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataframe(df, name ):\n",
    "    print(\"\\nEDA on: {}\".format(name))\n",
    "    # interested columns\n",
    "    columns = ['Character Name', 'Movie ID', 'Character ID']\n",
    "    for column in columns:\n",
    "        # check if dataframe contains a column named 'Character Name'\n",
    "        if column in df.columns:        \n",
    "            if column == 'Character Name':        \n",
    "                # Number of unique character names\n",
    "                print('Number of unique character names: {}'.format(df[column].nunique()))\n",
    "            if column == 'Movie ID':\n",
    "                # Number of unique movies\n",
    "                print('Number of unique movies: {}'.format(df[column].nunique()))\n",
    "            if column == 'Character ID':\n",
    "                # Number of unique character IDs\n",
    "                print('Number of unique character IDs: {}'.format(df[column].nunique()))\n",
    "            \n",
    "analyze_dataframe(df, \"movie_lines.txt df\")\n",
    "analyze_dataframe(df2, \"movie_characters_metadata.txt df\")\n",
    "analyze_dataframe(combined_df, \"Merged dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'messages': [{'role': 'system', 'content': 'You are an chatbot that is an expert in movie line quotes. You are limited to only answer movie related questions but can pull historical, or recent data to gain more context of the movie or what possible lines were said by characters. Inputs from an example of a raw script are: movie line, character, and movie title in that order. Ex: sack him?  david, what else can i do?  this business is not, repeat, not breaking even. and david  notice anything this morning?, GRIERSON, bean'}, {'role': 'user', 'content': 'Which character said this line sack him?  david, what else can i do?  this business is not, repeat, not breaking even. and david  notice anything this morning?, from the movie bean?'}]}, {'messages': [{'role': 'system', 'content': \"You are an chatbot that is an expert in movie line quotes. You are limited to only answer movie related questions but can pull historical, or recent data to gain more context of the movie or what possible lines were said by characters. Inputs from an example of a raw script are: movie line, character, and movie title in that order. Ex: that's right  worry about your clothes , CLAY, roughshod\"}, {'role': 'user', 'content': \"Which character said this line that's right  worry about your clothes , from the movie roughshod?\"}]}, {'messages': [{'role': 'system', 'content': \"You are an chatbot that is an expert in movie line quotes. You are limited to only answer movie related questions but can pull historical, or recent data to gain more context of the movie or what possible lines were said by characters. Inputs from an example of a raw script are: movie line, character, and movie title in that order. Ex: yes.  you're much too old to making a drama out of alienation, or whatever you call it.  you've got to take responsibility for your own happiness.  that's what i think anyway., SUSAN, the ploughman's lunch\"}, {'role': 'user', 'content': \"Which character said this line yes.  you're much too old to making a drama out of alienation, or whatever you call it.  you've got to take responsibility for your own happiness.  that's what i think anyway., from the movie the ploughman's lunch?\"}]}]\n"
     ]
    }
   ],
   "source": [
    "def create_training_ds(df, count= 10):\n",
    "    ds = []\n",
    "    \n",
    "    # give me 10 random samples in the processed utterance\n",
    "    # dynamically insert the movie line, character name, and movie title into the format template\n",
    "    sample = df.sample(count)\n",
    "    for index, row in sample.iterrows():\n",
    "        movie_title = row['Movie Title']\n",
    "        movie_line = row['process_utterance']\n",
    "        character_name = row['Character Name']\n",
    "\n",
    "        sys_cont = \"You are an chatbot that is an expert in movie line quotes. You are limited to only answer movie related questions but can pull historical, or recent data to gain more context of the movie or what possible lines were said by characters. Inputs from an example of a raw script are: movie line, character, and movie title in that order. Ex: {movie_line}, {character_name}, {movie_title}\".format(movie_line=movie_line, character_name=character_name, movie_title=movie_title)\n",
    "        user_cont = \"Which character said this line {movie_line}, from the movie {movie_title}?\".format(movie_line=movie_line, movie_title=movie_title)\n",
    "        \n",
    "        format_template = {\"messages\": [\n",
    "            {\"role\": \"system\", \"content\": sys_cont}, \n",
    "            {\"role\": \"user\", \"content\": user_cont}\n",
    "        ]}\n",
    "        ds.append(format_template.copy())\n",
    "    return ds\n",
    "\n",
    "data = create_training_ds(combined_df, 3)\n",
    "print(data) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  10\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(df, count= 10):\n",
    "    training_data = {\n",
    "        \"prompt\": [],\n",
    "        \"completion\": []\n",
    "    }\n",
    "    \n",
    "    # give me 10 random samples in the processed utterance\n",
    "    # dynamically insert the movie line, character name, and movie title into the format template\n",
    "    sample = df.sample(count)\n",
    "    for index, row in sample.iterrows():\n",
    "        movie_title = row['Movie Title']\n",
    "        movie_line = row['process_utterance']\n",
    "        character_name = row['Character Name']\n",
    "\n",
    "        sys_cont = \"You are an chatbot that is an expert in movie line quotes. You are limited to only answer movie related questions but can pull historical, or recent data to gain more context of the movie or what possible lines were said by characters. Inputs from an example of a raw script are: movie line, character, and movie title in that order. Ex: {movie_line}, {character_name}, {movie_title}\".format(movie_line=movie_line, character_name=character_name, movie_title=movie_title)\n",
    "        user_cont = \"Which character said this line {movie_line}, from the movie {movie_title}?\".format(movie_line=movie_line, movie_title=movie_title)\n",
    "        \n",
    "        training_data[\"prompt\"].append(sys_cont)\n",
    "        training_data[\"completion\"].append(user_cont)\n",
    "\n",
    "\n",
    "    return training_data\n",
    "\n",
    "\n",
    "ds2 = create_dataset(combined_df, 10)\n",
    "print(\"training data size: \", len(ds2[\"prompt\"]))\n",
    "\n",
    "def dict_to_jsonl(dictionary, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for prompt, completion in zip(dictionary[\"prompt\"], dictionary[\"completion\"]):\n",
    "            json_obj = {\"prompt\": prompt, \"completion\": completion}\n",
    "            json_line = json.dumps(json_obj)  # Convert dict to JSON string\n",
    "            file.write(json_line + '\\n')  # Write JSON string to file with newline\n",
    "    file.close()\n",
    "    return output_file\n",
    "\n",
    "\n",
    "file = dict_to_jsonl(ds2, \"training_data.jsonl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use file from the previous cell to invote the fine tune job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"bytes\": 5770,\n",
      "  \"created_at\": 1697769077,\n",
      "  \"filename\": \"file\",\n",
      "  \"id\": \"file-IJWH39SoQnC9b2q24PYr7fSW\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"status\": \"uploaded\",\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.File.create(\n",
    "    file=open(file),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not working yet to view status, says an email will be sent to Angel probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'FineTuningJob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/Steve/dev/GitProjects/Multi-turn-Chatbot-Design/final-group-chatbot.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Steve/dev/GitProjects/Multi-turn-Chatbot-Design/final-group-chatbot.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# View the status of the file\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Steve/dev/GitProjects/Multi-turn-Chatbot-Design/final-group-chatbot.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# List 10 fine-tuning jobs\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Steve/dev/GitProjects/Multi-turn-Chatbot-Design/final-group-chatbot.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m openai\u001b[39m.\u001b[39;49mFineTuningJob\u001b[39m.\u001b[39mlist(limit\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Steve/dev/GitProjects/Multi-turn-Chatbot-Design/final-group-chatbot.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Retrieve the state of a fine-tune\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Steve/dev/GitProjects/Multi-turn-Chatbot-Design/final-group-chatbot.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m openai\u001b[39m.\u001b[39mFineTuningJob\u001b[39m.\u001b[39mretrieve(\u001b[39m\"\u001b[39m\u001b[39mfile-DbZPjtA8PIj6LnL33X1LAi4D\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'FineTuningJob'"
     ]
    }
   ],
   "source": [
    "# View the status of the file\n",
    "# List 10 fine-tuning jobs\n",
    "openai.FineTuningJob.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "openai.FineTuningJob.retrieve(\"file-DbZPjtA8PIj6LnL33X1LAi4D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
